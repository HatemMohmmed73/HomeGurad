# -*- coding: utf-8 -*-
"""ETl & EDA

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/176VfsPm04Ab2ErmCFXz_sAcCWTIdkEv8

# Loading Data and clearning

## Environment Setup, Imports, and Configuration
"""

# 1. Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

pip install duckdb tensorflow

# 2. Standard Libraries
import sys
import os
import csv
import glob
import pickle
import warnings
from pathlib import Path

# 3. Data Manipulation
import pandas as pd
import numpy as np
import duckdb

# 4. Machine Learning & Metrics
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import StratifiedGroupKFold
from sklearn.ensemble import IsolationForest
from sklearn.decomposition import PCA
from sklearn.metrics import classification_report, confusion_matrix, f1_score, roc_auc_score

# 5. Deep Learning
import tensorflow as tf
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.optimizers import Adam

# 6. Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# 7. Configuration & Constants
# Define where  data lives
PROJECT_ROOT = Path("/content/drive/MyDrive/HOMEGUARD")
DATA_ROOT = PROJECT_ROOT / "01_data"
NOTEBOOKS_ROOT = PROJECT_ROOT / "02_notebooks"

# Define Benign Device IDs (Important for Splitting)
BENIGN_DEVICES = [
    "CTU-Honeypot-Capture-4-1", # Philips HUE
    "CTU-Honeypot-Capture-5-1", # Amazon Echo
    "CTU-Honeypot-Capture-7-1"  # Somfy Doorlock
]

# Ignore warnings for cleaner output
warnings.filterwarnings('ignore')

print(f" Project Root: {PROJECT_ROOT}")
print(f" Data Directory: {DATA_ROOT}")

"""## Exploratory Data Analysis - Examining Raw Logs
Understand the structure of Zeek logs to determine how to parse them.

"""

sample_file = list(DATA_ROOT.glob("**/conn.log.labeled"))[0]
print(f" Inspecting raw file: {sample_file}")

# Let's look at the first 10 lines to see the header format
with open(sample_file, 'r') as f:
    for i in range(10):
        print(f.readline().strip())

"""## Developing the Custom Header Parser

We define a function to interpret the metadata lines (#fields, #types)

which is found in the exploration phase, allowing us to dynamically adapt to different log files.
"""

def parse_zeek_header(header_lines):
    """
    Parses Zeek log headers to extract the separator, field names, and column types.
    """
    separator = "\t"
    fields = []
    types = []

    for line in header_lines:
        parts = line.strip().split()
        if not parts: continue

        # 1. Detect the separator (usually tab \x09)
        if parts[0] == "#separator":
            if parts[1].startswith("\\x"):
                separator = chr(int(parts[1][2:], 16))
            else:
                separator = parts[1]

        # 2. Extract column names
        elif parts[0] == "#fields":
            # Skip the first element which is '#fields'
            fields = line.strip().split(separator)[1:]

        # 3. Extract column types
        elif parts[0] == "#types":
            types = line.strip().split(separator)[1:]

    return separator, fields, types

"""## Streaming Generator

Problem: Loading entire logs into RAM causes crashes due to dataset size.
A generator function that yields one processed row at a time.
"""

def stream_parse_zeek_file(filepath):
    """
    Generator that reads a Zeek log line-by-line, handling headers and
    malformed label columns automatically.
    """
    with open(filepath, 'r', encoding='utf-8', errors='replace') as f:
        header_lines = []

        # 1. Read headers until the first data line
        while True:
            pos = f.tell()
            line = f.readline()
            if not line: break

            if line.startswith("#"):
                header_lines.append(line)
            else:
                # We hit data; step back one line so we don't miss it
                f.seek(pos)
                break

        # Parse the header we just read
        separator, fields, _ = parse_zeek_header(header_lines)

        # 2. Stream and Process Data Rows
        for line in f:
            if line.startswith("#"): continue # Skip footers

            values = line.strip().split(separator)

            # --- Data Cleaning Logic ---
            # Fix for IoT-23 "Combined Label" issue:
            # Sometimes the label field contains spaces which confuse standard splitters.
            if len(values) > len(fields):
                # Merge extra columns into the last field (the Label)
                values[len(fields)-1] = " ".join(values[len(fields)-1:])
                values = values[:len(fields)]
            elif len(values) < len(fields):
                # Pad missing values with None
                values += [None] * (len(fields) - len(values))

            # Yield a clean dictionary
            yield dict(zip(fields, values))

# We test the parser on the Philips HUE dataset before scaling up.

print(f"Testing on: {sample_file.name}")

buffer = []
for i, row in enumerate(stream_parse_zeek_file(sample_file)):
    if i >= 5: break
    buffer.append(row)

df_test = pd.DataFrame(buffer)
print("Parser Output Preview:")
display(df_test)
df_test.info()

"""## Full ETL Execution
scale the parsing logic across the entire dataset.
"""

# 1. Define Output Path
RAW_OUTPUT_PATH = NOTEBOOKS_ROOT / "file.parquet"



# 3. Define Device Labels (Ground Truth)
# We map the specific folder names to the actual IoT devices
BENIGN_MAP = {
    "CTU-Honeypot-Capture-4-1": "Philips HUE",
    "CTU-Honeypot-Capture-5-1": "Amazon Echo",
    "CTU-Honeypot-Capture-7-1": "Somfy Doorlock"
}

# 4. Processing Loop
# We locate all files recursively
all_files = sorted(list(DATA_ROOT.glob("**/conn.log.labeled")))
print(f"Starting processing of {len(all_files)} files")

chunk_buffer = []
chunk_size = 100000 # Write every 100k rows to save RAM
total_rows = 0

for file_path in all_files:
    # Extract metadata from file path
    capture_id = file_path.parent.parent.name
    device = BENIGN_MAP.get(capture_id, "Malicious")

    print(f"   -> Processing {capture_id} ({device})")

    # Use our custom generator
    for row in stream_parse_zeek_file(file_path):
        row['capture_id'] = capture_id
        row['device'] = device
        chunk_buffer.append(row)

        # Write to disk when buffer is full
        if len(chunk_buffer) >= chunk_size:
            df = pd.DataFrame(chunk_buffer)

            # Append to parquet (creates file if not exists, appends otherwise)
            if not os.path.exists(RAW_OUTPUT_PATH):
                df.to_parquet(RAW_OUTPUT_PATH, engine='fastparquet', index=False)
            else:
                df.to_parquet(RAW_OUTPUT_PATH, engine='fastparquet', append=True, index=False)

            total_rows += len(chunk_buffer)
            chunk_buffer = [] # Clear memory immediately

# Save any remaining data in the buffer
if chunk_buffer:
    df = pd.DataFrame(chunk_buffer)
    if not os.path.exists(RAW_OUTPUT_PATH):
        df.to_parquet(RAW_OUTPUT_PATH, engine='fastparquet', index=False)
    else:
        df.to_parquet(RAW_OUTPUT_PATH, engine='fastparquet', append=True, index=False)
    total_rows += len(chunk_buffer)

print(f" Total Rows Processed: {total_rows}")
print(f"Data saved to: {RAW_OUTPUT_PATH}")

"""##   Data Cleaning with DuckDB

Clean the raw "file.parquet", fix the combined label columns, and save as "final_clean.parquet".

"""

import duckdb

# Define input/output paths based on  file structure
RAW_INPUT = NOTEBOOKS_ROOT / "file.parquet"
CLEAN_OUTPUT = NOTEBOOKS_ROOT / "final_clean.parquet"


# We use DuckDB to run SQL directly on the Parquet file
# This splits the combined 'tunnel_parents' string into proper labels
con = duckdb.connect()

# 2. Define the SQL Transformation
query = f"""
COPY (
    SELECT
        -- A. Feature Selection: Keep only model-relevant columns
        -- We drop 'uid', 'id.orig_h', 'id.resp_h' to prevent the model from
        -- simply memorizing specific IPs or connection IDs (Data Leakage).
        "id.orig_p",
        "id.resp_p",
        "proto",
        "service",
        "duration",
        "orig_bytes",
        "resp_bytes",
        "conn_state",
        "missed_bytes",
        "history",
        "orig_pkts",
        "orig_ip_bytes",
        "resp_pkts",
        "resp_ip_bytes",

        -- B. Metadata Preservation (Needed for splitting/windowing later)
        "ts",
        "capture_id",

        -- C. Label Cleaning (Fixing the IoT-23 combined label issue)
        -- Regex logic: Finds the second word in the string.
        -- Input: "-   benign   -"  -> Output: "benign"
        lower(trim(regexp_extract(tunnel_parents, '^\\S+\\s+(\\S+)', 1))) AS label_clean,

        -- D. Malicious Subtype Extraction (Optional, good for analysis)
        CASE
            WHEN lower(trim(regexp_extract(tunnel_parents, '^\\S+\\s+(\\S+)', 1))) = 'malicious'
            THEN nullif(trim(regexp_extract(tunnel_parents, '^\\S+\\s+\\S+\\s+(.*)$', 1)), '-')
            ELSE NULL
        END AS malicious_type

    FROM read_parquet('{RAW_INPUT}')
    WHERE label_clean IN ('benign', 'malicious') -- Filter out unlabelled/garbage rows
)
TO '{CLEAN_OUTPUT}' (FORMAT PARQUET);
"""

# 3. Execute
if not os.path.exists(CLEAN_OUTPUT):
    print(" Running DuckDB Transformation...")
    con.execute(query)
    print(" Transformation Complete.")
else:
    print(" Clean file already exists. Skipping computation to save time.")

# 4. Verification
print("\n Verifying Cleaned Data Schema:")
# Read just 5 rows to check if columns are correct
df_preview = duckdb.query(f"SELECT * FROM read_parquet('{CLEAN_OUTPUT}') LIMIT 5").df()
display(df_preview)

"""## Compare the 'Raw' ingestion against the 'Cleaned' version to validate our parsing logic.

"""

import duckdb
import pandas as pd

# Define the paths to the existing files
RAW_FILE = "/content/drive/MyDrive/HOMEGUARD/02_notebooks/file.parquet"
CLEAN_FILE = "/content/drive/MyDrive/HOMEGUARD/02_notebooks/final_clean.parquet"

con = duckdb.connect()

print(" 1. INSPECTING RAW FILE (file.parquet)")
print("-" * 50)

# Get Schema Info
raw_schema = con.execute(f"DESCRIBE SELECT * FROM read_parquet('{RAW_FILE}')").df()
print(f"Total Columns: {len(raw_schema)}")
print("Columns:", raw_schema['column_name'].tolist())

# Get a sample row (specifically looking for the messy label column)
print("\n--- Raw Sample Row (Focus on 'tunnel_parents') ---")
raw_sample = con.execute(f"""
    SELECT "tunnel_parents", "id.orig_p", "proto"
    FROM read_parquet('{RAW_FILE}')
    LIMIT 3
""").df()
display(raw_sample)


print("\n\n 2. INSPECTING CLEAN FILE (final_clean.parquet)")
print("-" * 50)

# Get Schema Info
clean_schema = con.execute(f"DESCRIBE SELECT * FROM read_parquet('{CLEAN_FILE}')").df()
print(f"Total Columns: {len(clean_schema)}")
print("Columns:", clean_schema['column_name'].tolist())

# Get a sample row (Looking for the extracted labels)
print("\n--- Clean Sample Row (Focus on 'label_clean') ---")
clean_sample = con.execute(f"""
    SELECT "label_clean", "malicious_type", "id.orig_p", "proto"
    FROM read_parquet('{CLEAN_FILE}')
    LIMIT 3
""").df()
display(clean_sample)

print("\n VERIFICATION:")
if 'label_clean' in clean_schema['column_name'].values:
    print("Pass: 'label_clean' column exists in the clean file.")
else:
    print("Fail: 'label_clean' is missing.")

"""## Analyzing Capture Distribution for Splitting Strategy

Determine which Capture IDs should go to Train, Validation, and Test.

"""

import duckdb
import pandas as pd

CLEAN_FILE = NOTEBOOKS_ROOT / "final_clean.parquet"

print(f"Analyzing: {CLEAN_FILE}")

con = duckdb.connect()

# 1. Get statistics per Capture ID
# We use SQL aggregation to avoid loading millions of rows into RAM
capture_stats = con.execute(f"""
    SELECT
        capture_id,
        COUNT(*) as total_rows,
        SUM(CASE WHEN label_clean = 'benign' THEN 1 ELSE 0 END) as benign_count,
        SUM(CASE WHEN label_clean = 'malicious' THEN 1 ELSE 0 END) as mal_count
    FROM read_parquet('{CLEAN_FILE}')
    GROUP BY capture_id
    ORDER BY benign_count DESC
""").df()

# 2. Display the candidates for our split
print("\Capture Scenarios Available ")
display(capture_stats)

print("\n Proposed Research Split Strategy ")
print("1. TRAIN:  High-volume Benign devices (e.g., Philips HUE, Amazon Echo).")
print("2. VALID:  Unseen Benign device (Somfy Doorlock) ")
print("3. TEST:   All remaining Malicious captures + sample of Benign.")

"""## Splitting Strategy (3-Fold Cross Validation)

Create specific experimental folds to test generalization across different IoT devices.

"""

# Research Splitting Strategy (3-Fold Cross Validation)
# Create specific experimental folds to test generalization across different IoT devices.

import duckdb

# 1. Define The Benign Device Groups
# These match the specific Capture IDs in the dataset
devices = {
    "Philips": "CTU-Honeypot-Capture-4-1",
    "Echo":    "CTU-Honeypot-Capture-5-1",
    "Doorlock":"CTU-Honeypot-Capture-7-1"
}

# 2. Define the Folds (Leave-One-Group-Out Strategy)
# Fold 1: Train on Philips+Echo, Validate on Doorlock
# Fold 2: Train on Philips+Doorlock, Validate on Echo
# Fold 3: Train on Echo+Doorlock, Validate on Philips
folds = [
    ([devices["Philips"], devices["Echo"]],     [devices["Doorlock"]]), # Fold 1
    ([devices["Philips"], devices["Doorlock"]], [devices["Echo"]]),     # Fold 2
    ([devices["Echo"],    devices["Doorlock"]], [devices["Philips"]])   # Fold 3
]

con = duckdb.connect()

# 3. Generate the Files
print("Executing 3-Fold Split Strategy...")

for i, (train_ids, valid_ids) in enumerate(folds, start=1):
    print(f"\n Generating Fold {i}")

    # Helper to format list for SQL: 'ID1', 'ID2'
    train_sql = ", ".join([f"'{x}'" for x in train_ids])
    valid_sql = ", ".join([f"'{x}'" for x in valid_ids])

    # A. Create Train File (Benign data from Train IDs)
    train_path = DATA_ROOT / f"train_fold{i}.parquet"
    con.execute(f"""
        COPY (
            SELECT * FROM read_parquet('{CLEAN_FILE}')
            WHERE capture_id IN ({train_sql})
            AND label_clean = 'benign'
        ) TO '{train_path}' (FORMAT PARQUET);
    """)
    print(f"    Saved Train: {train_path.name} (Devices: {train_ids})")

    # B. Create Validation File (Benign data from Valid ID - Unseen Device)
    valid_path = DATA_ROOT / f"valid_fold{i}.parquet"
    con.execute(f"""
        COPY (
            SELECT * FROM read_parquet('{CLEAN_FILE}')
            WHERE capture_id IN ({valid_sql})
            AND label_clean = 'benign'
        ) TO '{valid_path}' (FORMAT PARQUET);
    """)
    print(f"    Saved Valid: {valid_path.name} (Device: {valid_ids})")

# 4. Generate the Master Test Set (All Malicious Data)
# The Test set represents "The Wild" - containing all attacks from all scenarios.
print("\n--- Generating Master Test Set ---")
test_path = DATA_ROOT / "test.parquet"
benign_ids_all = list(devices.values())
benign_sql = ", ".join([f"'{x}'" for x in benign_ids_all])

con.execute(f"""
    COPY (
        SELECT * FROM read_parquet('{CLEAN_FILE}')
        WHERE label_clean = 'malicious'
           OR capture_id NOT IN ({benign_sql}) -- Include any benign data from non-target devices if any
    ) TO '{test_path}' (FORMAT PARQUET);
""")
print(f"Saved Test: {test_path.name} (All Malicious Traffic)")

"""# EDA

## Define our File Paths and loding data
"""

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd

TRAIN_PATH = "/content/drive/MyDrive/HOMEGUARD/01_data/train_fold1.parquet"
VALID_PATH = "/content/drive/MyDrive/HOMEGUARD/01_data/valid_fold1.parquet"
TEST_PATH  = "/content/drive/MyDrive/HOMEGUARD/test_sample_1M.parquet"

try:
    train_df = pd.read_parquet(TRAIN_PATH)
    valid_df = pd.read_parquet(VALID_PATH)
    test_df  = pd.read_parquet(TEST_PATH)
except Exception as e:
    print(f" Error loading data: {e}")

"""## Verify Class Distributions

"""

def check_distribution(name, df):
    print(f"\n{name} Set Shape: {df.shape}")
    if 'label_clean' in df.columns:
        counts = df['label_clean'].value_counts()
        print(counts)
    else:
        print(f"Column 'label_clean' not found in {name}")

check_distribution("TRAIN", train_df)
check_distribution("VALID", valid_df)
check_distribution("TEST", test_df)

"""Train (1,826 rows) is tiny compared to Test (1M rows). This is risky. If "Normal" behavior varies a lot, 1,826 samples might not be enough to learn it all. But let's proceed; if we fail later, we know we need more training data.
Test Set Imbalance: The test set is ~90% Malicious. This means a "dumb" model that predicts everything is Malicious would have 90% accuracy. We cannot use Accuracy. We must use Precision and Recall.

"""

train_df.columns

print("\n Forensic Check: Malicious Type Distribution ")

# 1. Check the full Test set (since the sample might be skewed)
# We focus on the 'malicious' rows in the original test_df
malicious_types = test_df[test_df["label_clean"] == "malicious"]["malicious_type"].value_counts()

print(f"Total Malicious Flows in Test Set: {malicious_types.sum():,}")
print("\nDistribution of Malicious Types:")
print(malicious_types)

# 2. Visualize the top types
plt.figure(figsize=(10, 5))
sns.barplot(x=malicious_types.index, y=malicious_types.values, palette="Reds_d")
plt.xticks(rotation=45, ha='right')
plt.title("Malicious Type Distribution in Test Set")
plt.ylabel("Count (Log Scale)")
plt.yscale('log') # Use log scale to see if rare types exist
plt.tight_layout()
plt.show()

"""## The Physics of Traffic (Numerical Analysis)"""

# 1. Isolate Malicious traffic from Test for comparison
malicious_sample = test_df[test_df["label_clean"] == "malicious"].sample(n=2000, random_state=42)

# 2. Define features to inspect
features_to_check = ['orig_bytes', 'resp_bytes', 'duration', 'orig_pkts']

# 3. Plot Distributions (Log Scale is CRITICAL for Network Data)
plt.figure(figsize=(15, 10))

for i, feature in enumerate(features_to_check):
    plt.subplot(2, 2, i+1)

    # We use log1p (log(1+x)) to handle zeros and huge values
    sns.kdeplot(np.log1p(train_df[feature]), label='Benign (Train)', fill=True, color='blue', alpha=0.3)
    sns.kdeplot(np.log1p(malicious_sample[feature]), label='Malicious (Sample)', fill=True, color='red', alpha=0.3)

    plt.title(f"Distribution of {feature} (Log Scale)")
    plt.xlabel(f"Log(1 + {feature})")
    plt.legend()

plt.tight_layout()
plt.show()

"""The "Zero" Spike: For all four features, the Malicious traffic (red) has an overwhelmingly sharp peak right at Log(1+x)≈0
.

 This means most malicious connections are: zero-byte (orig_bytes, resp_bytes), instantaneous (duration), and single-packet (orig_pkts). This is the signature of failed connections, network scans, and single-packet beaconing.




The "Success" Spread: The Benign traffic (blue) is much more spread out, forming wider, lower peaks to the right of zero.

Benign traffic is characterized by longer conversations, successful data transfer, and variability.

Modeling Strategy: The model's job will be to learn the shape and density of the wide, blue distribution and flag anything that falls into the sharp red spike near zero. This confirms the choice of Anomaly Detection/Novelty Detection.
"""

# Prepare a combined view for comparison
# We take all of Train (Benign) and a random sample of Test (Malicious)
# This gives us a clean "Normal vs Attack" view.
eda_benign = train_df.copy()
eda_benign['type'] = 'Benign (Baseline)'

eda_malicious = test_df[test_df['label_clean'] == 'malicious'].sample(n=5000, random_state=42).copy()
eda_malicious['type'] = 'Malicious (Test)'

eda_combined = pd.concat([eda_benign, eda_malicious], axis=0)

# Define features that represent "Physics" (Size and Time)
phys_features = ['orig_bytes', 'resp_bytes', 'duration', 'orig_pkts', 'resp_pkts']

plt.figure(figsize=(20, 12))

for i, col in enumerate(phys_features):
    plt.subplot(2, 3, i+1)

    # We add a small epsilon (1e-5) to avoid log(0) errors
    # We use Boxenplot because it shows the shape of the tails better than Boxplot
    sns.boxenplot(data=eda_combined, x='type', y=col, hue='type', palette={'Benign (Baseline)': 'blue', 'Malicious (Test)': 'red'})
    plt.yscale('log') # CRITICAL: Network data is exponential
    plt.title(f'{col} Distribution (Log Scale)', fontsize=12)
    plt.xlabel('')
    plt.ylabel('Value (Log)')

plt.tight_layout()
plt.show()

"""For all five features, the malicious traffic (red) is concentrated at the absolute bottom of the log scale.

1. duration

Benign (blue) spans from 10^-4 to 10^1.

Malicious (red) is almost entirely compressed into the 10^-5 (zero/instantaneous) region.
 This is the strongest single-feature difference.

2. orig_bytes, resp_bytes, orig_pkts, resp_pkts

The malicious distributions are collapsed near 10^0 or 10^-5,
indicating no data transfer or very short, single-packet flows.

## The Logic of Connections (Categorical Analysis)
"""

fig, axes = plt.subplots(1, 3, figsize=(20, 6))

# Connection State Analysis
# We normalize (normalize=True) to see percentages, because the counts are vastly different
state_counts = eda_combined.groupby(['type', 'conn_state']).size().reset_index(name='count')
total_counts = eda_combined.groupby('type')['type'].count()
state_counts['percentage'] = state_counts.apply(lambda x: x['count'] / total_counts[x['type']], axis=1)

sns.barplot(data=state_counts, x='conn_state', y='percentage', hue='type', ax=axes[0], palette={'Benign (Baseline)': 'blue', 'Malicious (Test)': 'red'})
axes[0].set_title("Connection State Distribution (The 'Handshake' Logic)")
axes[0].set_yscale('log') # Log scale to see rare states

# Protocol Analysis
proto_counts = eda_combined.groupby(['type', 'proto']).size().reset_index(name='count')
proto_counts['percentage'] = proto_counts.apply(lambda x: x['count'] / total_counts[x['type']], axis=1)

sns.barplot(data=proto_counts, x='proto', y='percentage', hue='type', ax=axes[1], palette={'Benign (Baseline)': 'blue', 'Malicious (Test)': 'red'})
axes[1].set_title("Protocol Distribution")

service = eda_combined.groupby(['type', 'service']).size().reset_index(name='count')
service['percentage'] = service.apply(lambda x: x['count'] / total_counts[x['type']], axis=1)

sns.barplot(data=service, x='service', y='percentage', hue='type', ax=axes[2], palette={'Benign (Baseline)': 'blue', 'Malicious (Test)': 'red'})
axes[2].set_title("service Distribution")

plt.tight_layout()
plt.show()

"""### Connection State (The “Handshake” Logic)

#### **Malicious Dominance — Scanning / Failure**

* The malicious set (red) is overwhelmingly dominated by the **`S0`** state.

  * **`S0`** = SYN sent, no response received  a failed or ignored connection attempt.
  * This is the canonical signature of **port scanning**.

#### **Benign Dominance — Success / Completion**

The benign set (blue) has high proportions of:

* **`SF`** — Successful, fully established, and properly terminated connection.
* **`S1`, `S3`, `SH`** — Successful setup and transfer, or partial but legitimate completions.
* **`RSTR`** — Reset by responder (normal for legitimate server-side rejections).

**Key Signal:**
The extreme contrast between **`S0` (malicious)** and **`SF` (benign)** is a strong and quantifiable detection feature.


### Protocol Distribution

#### **Malicious Focus**

* Malicious traffic is almost **100% `tcp`**.
* This aligns with typical scanning and exploit behavior, which commonly relies on TCP handshakes.

#### **Benign Variety**

* Benign traffic includes:

  * ~35% **`tcp`**
  * ~60% **`udp`**
* High UDP presence reflects normal DNS, streaming, and service discovery traffic.

**Key Signal:**
Although TCP alone isn’t suspicious, the **absence of UDP** is a strong indicator that the traffic is **not normal for this environment**.

## The Hidden Relationships (Correlation on TRAIN)
"""

# Select only numeric columns
numeric_train = train_df.select_dtypes(include=['int64', 'float64'])

# Drop columns with 0 variance (if any)
numeric_train = numeric_train.loc[:, numeric_train.std() > 0]

plt.figure(figsize=(12, 10))
correlation_matrix = numeric_train.corr()

# Draw the heatmap
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm', vmin=-1, vmax=1)
plt.title("Feature Correlation Matrix (Benign Training Data)")
plt.show()

"""### Heatmap Interpretation — Redundancy & Collinearity

The heatmap shows **substantial feature redundancy**, which can destabilize some models (e.g., linear regression), though **non-linear models** like **Isolation Forest** and **Autoencoders** are more robust to it.


### Extreme Collinearity (Correlation = **1.00**)

* **`resp_bytes` ↔ `resp_ip_bytes`**
* **`orig_pkts` ↔ `orig_ip_bytes`**
* **`resp_pkts` ↔ `orig_pkts`**

**Interpretation:**
When one value increases, the other **always** increases proportionally. These features are effectively **statistical duplicates**, carrying the same information.


### High Collinearity (Correlation = **0.84 – 0.88**)

* **`orig_ip_bytes`** has high correlation with `orig_pkts` and `resp_pkts`.
* **`resp_ip_bytes`** has high correlation with `orig_pkts` and `resp_pkts`.

**Interpretation:**
As packet counts rise, total byte counts also rise — expected behavior.
However, this means these variables are **redundant inputs**, all conveying the same underlying relationship between packet count and byte volume.

## Behavioral Analysis
"""

# Create a working copy for analysis
df_analysis = eda_combined.copy()

# Feature Engineering for Insight (Not for the model yet, just for us)
# Avoid division by zero
df_analysis['duration'] = df_analysis['duration'].replace(0, 0.0001)

# A. Throughput (Bytes per second) - "Is it a heavy flood?"
df_analysis['bytes_per_sec'] = (df_analysis['orig_bytes'] + df_analysis['resp_bytes']) / df_analysis['duration']

# B. Packet Density (Bytes per packet) - "Is it sending empty headers or real data?"
# (Small avg bytes = Scanning/Control; Large avg bytes = Data Transfer)
df_analysis['bytes_per_pkt'] = (df_analysis['orig_bytes'] + df_analysis['resp_bytes']) / (df_analysis['orig_pkts'] + df_analysis['resp_pkts'])

# C. Symmetry (Ratio of incoming to outgoing) - "Is the conversation one-sided?"
# +1 to avoid division by zero.
# Ratio ~ 1 means balanced conversation. Ratio near 0 or huge means one-sided.
df_analysis['byte_ratio'] = (df_analysis['resp_bytes'] + 1) / (df_analysis['orig_bytes'] + 1)


# --- VISUALIZATION ---
fig, axes = plt.subplots(1, 3, figsize=(24, 6))

# Plot 1: The Speed (Bytes/Sec)
sns.boxenplot(data=df_analysis, x='type', y='bytes_per_sec', hue='type', ax=axes[0], palette={'Benign (Baseline)': 'blue', 'Malicious (Test)': 'red'})
axes[0].set_yscale('log')
axes[0].set_title("Attack Speed: Throughput (Bytes/Sec)")

# Plot 2: The Payload (Bytes/Packet)
sns.boxenplot(data=df_analysis, x='type', y='bytes_per_pkt', hue='type', ax=axes[1], palette={'Benign (Baseline)': 'blue', 'Malicious (Test)': 'red'})
axes[1].set_yscale('log')
axes[1].set_title("Packet Density: Are they empty packets?")

# Plot 3: The Conversation (Response/Origin Ratio)
sns.boxenplot(data=df_analysis, x='type', y='byte_ratio', hue='type', ax=axes[2], palette={'Benign (Baseline)': 'blue', 'Malicious (Test)': 'red'})
axes[2].set_yscale('log')
axes[2].set_title("Symmetry: Response / Origin Ratio")
axes[2].axhline(1, color='green', linestyle='--', label="Balanced (1.0)") # Reference line

plt.tight_layout()
plt.show()

"""### Flow-Derived Metrics

The plots for **malicious (red)** traffic show highly collapsed, low-variance behavior — a hallmark of scanning or failed handshakes.



#### **Attack Speed (Bytes/Sec)**

* **Malicious : Near Zero**
  The red box is compressed at the bottom, indicating **zero or near-zero transfer rate**.
  This is characteristic of **non–data-carrying scans** or **failed TCP handshakes**.

* **Benign : Highly Variable**
  The blue box spans several orders of magnitude, reflecting **successful and diverse data transfer rates**.



#### **Packet Density (Bytes/Packet)**

* **Malicious : Near Zero**
  The red box sits at the bottom of the scale, showing that malicious flows consist of **packets with little or no payload** (mostly just headers).

* **Benign : High**
  The blue box has large values, indicating that legitimate flows carry **substantial payload data**, often hundreds of bytes per packet.



#### **Symmetry (Response/Origin Ratio)**

* **Malicious: One-Sided (Ratio < 1)**
  The red box is tiny and remains **below the 1.0 line**, indicating that flows are **unidirectional** — the client sends but the server doesn't respond.
  This matches the *S0* connection-state pattern and reinforces the **port-scan** interpretation.

* **Benign : Balanced (Ratio ≈ 1.0)**
  The blue box is centered tightly around the **1.0** (green dashed) line, the hallmark of a **successful, symmetric TCP exchange** where each request receives a reply.

## The Missing Signals & Port Logic
"""

# Analyze Missing Values by Class
# We need to see if "Missing Data" is correlated with "Maliciousness"
missing_analysis = pd.DataFrame({
    'Column': train_df.columns,
    'Benign_Nulls': train_df.isnull().sum(),
    'Malicious_Nulls (Sample)': malicious_sample.isnull().sum() # Re-using our sample from before
})
print(" Missing Value Counts:")
print(missing_analysis[missing_analysis['Benign_Nulls'] > 0])


#  Port Analysis (The "Target" Logic)
# We want to see the Top 10 Destination Ports for Benign vs Malicious
fig, axes = plt.subplots(1, 2, figsize=(20, 6))

# Benign Ports
top_benign_ports = train_df['id.resp_p'].value_counts().head(10)
sns.barplot(x=top_benign_ports.index.astype(str), y=top_benign_ports.values, ax=axes[0], color='blue')
axes[0].set_title("Top 10 Destination Ports (Benign)")
axes[0].set_xlabel("Port Number")
axes[0].set_ylabel("Count")

# Malicious Ports
top_mal_ports = malicious_sample['id.resp_p'].value_counts().head(10)
sns.barplot(x=top_mal_ports.index.astype(str), y=top_mal_ports.values, ax=axes[1], color='red')
axes[1].set_title("Top 10 Destination Ports (Malicious Sample)")
axes[1].set_xlabel("Port Number")

plt.tight_layout()
plt.show()


# 3. Service Analysis (The "Unknown" Factor)
# Fill NaNs with "unknown" to see if "unknown" is actually a signal
train_df['service_filled'] = train_df['service'].fillna('unknown')
malicious_sample['service_filled'] = malicious_sample['service'].fillna('unknown')

fig, axes = plt.subplots(1, 2, figsize=(20, 6))

# Benign Service
top_ben_srv = train_df['service_filled'].value_counts().head(10)
sns.barplot(x=top_ben_srv.index, y=top_ben_srv.values, ax=axes[0], color='blue')
axes[0].set_title("Top Services (Benign)")

# Malicious Service
top_mal_srv = malicious_sample['service_filled'].value_counts().head(10)
sns.barplot(x=top_mal_srv.index, y=top_mal_srv.values, ax=axes[1], color='red')
axes[1].set_title("Top Services (Malicious)")

plt.tight_layout()
plt.show()

"""### Missing Value Analysis (The Imputation Signal)

#### **Malicious: Missing Data**

* Malicious flows have **high NaN counts** for `duration` and `bytes`.
* This is expected because most malicious flows are **`S0`** (failed or instantaneous connections), where these fields are **never recorded**.

**Interpretation:**
Our pipeline should impute these values as **0**, and the *presence of missingness itself* is a **strong anomaly signal**.



### Service Analysis (The “Unknown” Attack)

#### **Malicious : `unknown`**

* **100% of the malicious traffic** is labeled as **`unknown`**.

**Interpretation:**
This is a **huge signal**.
Zeek/Bro assigns `unknown` when it cannot determine the application-layer protocol, often because the traffic is:

* on non-standard ports
* carrying malformed payloads
* extremely short or incomplete
* part of a scan

Therefore, **`service = 'unknown'` is an extremely strong feature** for identifying malicious activity.

#### **Benign Mix**

* Benign traffic includes normal services such as:

  * `dns`
  * `http`
  * `dhcp`
  * some `unknown` (expected background noise)



### Port Analysis (The “Target” Signal)

#### **Malicious Ports**

* The plot isn’t shown, but the logic remains clear: malicious flows typically involve:

  * **wide port coverage** (port scanning)
  * or **targeting unusual/high-value ports**

In many attack scenarios, scans probe **high port numbers**, while benign flows concentrate on well-known ones.

#### **Benign Ports**

* Benign traffic usually clusters around common service ports:

  * **80**, **443**, **53**, etc.

## History DNA Forensics
"""

#  Feature Engineering for visualization
df_analysis['history_filled'] = df_analysis['history'].fillna('')

# Did a data transfer occur?
df_analysis['has_Data'] = df_analysis['history_filled'].str.contains('D').astype(int)

# Was it a simple, one-sided SYN-Scan?
df_analysis['is_Syn_Only'] = (df_analysis['history_filled'] == 'S').astype(int)

# What is the complexity of the conversation?
df_analysis['history_length'] = df_analysis['history_filled'].str.len()

# 2. Visualization
fig, axes = plt.subplots(1, 3, figsize=(20, 6))

# Plot 1: Has Data (D)
sns.barplot(data=df_analysis, x='type', y='has_Data', hue='type', ax=axes[0], palette={'Benign (Baseline)': 'blue', 'Malicious (Test)': 'red'})
axes[0].set_title("Proportion of Flows Containing Data ('D')")

# Plot 2: Is SYN Only (S)
sns.barplot(data=df_analysis, x='type', y='is_Syn_Only', hue='type', ax=axes[1], palette={'Benign (Baseline)': 'blue', 'Malicious (Test)': 'red'})
axes[1].set_title("Proportion of Simple SYN Scans ('S')")

# Plot 3: History Length
sns.boxenplot(data=df_analysis, x='type', y='history_length', hue='type', ax=axes[2], palette={'Benign (Baseline)': 'blue', 'Malicious (Test)': 'red'})
axes[2].set_title("Conversation Complexity (History Length)")

plt.tight_layout()
plt.show()

"""

### History String Analysis (Flow Behavior Signals)

#### **Proportion of Flows Containing Data (`D`)**

* **Benign → ~80% contain `D`**
  Most benign flows exchange real application data.

* **Malicious → 0% (or near 0%) contain `D`**
  Malicious flows do **not** transfer data.

**Interpretation:**
Malicious flows exist for **control, scanning, or probing**, not data exchange.
This feature alone is almost a **perfect binary classifier**.



#### **Proportion of Simple SYN Scans (`S`)**

* **Malicious → ~100% are simple SYN attempts**
  The history string is just `'S'` (or equivalent variants).

* **Benign → 0% (or near 0%) are simple SYN-only flows**
  Benign traffic almost always proceeds past the initial SYN.

**Interpretation:**
Malicious traffic is dominated by **single-packet SYN scans** with no continuation — classic port scan behavior.



#### **Conversation Complexity (History Length)**

* **Benign → Length 2–6 characters**
  Reflects full TCP handshakes, data exchange, and clean shutdowns.

* **Malicious → Length ≈ 1**
  Collapsed to a single character (`"S"`), indicating no reply and no conversation.

**Interpretation:**
This metric provides the **numeric confirmation** of the earlier finding:

* Benign flows represent **two-sided conversations**.
* Malicious flows represent **one-sided scans**.


"""